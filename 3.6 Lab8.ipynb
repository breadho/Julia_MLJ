{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a642f4cf",
   "metadata": {},
   "source": [
    "# Intro to Stats Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ff9b1",
   "metadata": {},
   "source": [
    "## Lab 8 - Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ad015",
   "metadata": {},
   "source": [
    "> https://juliaai.github.io/DataScienceTutorials.jl/isl/lab-8/\n",
    "> <br> (project folder) https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a48778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `D:\\JULIA\\6_ML_with_Julia\\ISL-lab-8`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\"D:/JULIA/6_ML_with_Julia/ISL-lab-8\"); Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d48da",
   "metadata": {},
   "source": [
    "Getting started\n",
    "1. Decision Tree Classifier\n",
    "2. Tuning a DTC\n",
    "3. Decision Tree Regressor <br>\n",
    "\n",
    "Random Forest <br>\n",
    "Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c8c6b",
   "metadata": {},
   "source": [
    "### Getting started \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97703dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n",
      "┌────────────┬────────────┬────────────┬─────────────┬────────────┬────────────┬─────────────────────────────────┬────────────┬────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
      "│\u001b[1m Sales      \u001b[0m│\u001b[1m CompPrice  \u001b[0m│\u001b[1m Income     \u001b[0m│\u001b[1m Advertising \u001b[0m│\u001b[1m Population \u001b[0m│\u001b[1m Price      \u001b[0m│\u001b[1m ShelveLoc                       \u001b[0m│\u001b[1m Age        \u001b[0m│\u001b[1m Education  \u001b[0m│\u001b[1m Urban                           \u001b[0m│\u001b[1m US                              \u001b[0m│\n",
      "│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64     \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{String, UInt8} \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m Float64    \u001b[0m│\u001b[90m CategoricalValue{String, UInt8} \u001b[0m│\u001b[90m CategoricalValue{String, UInt8} \u001b[0m│\n",
      "│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous  \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{3}                   \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Continuous \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\u001b[90m Multiclass{2}                   \u001b[0m│\n",
      "├────────────┼────────────┼────────────┼─────────────┼────────────┼────────────┼─────────────────────────────────┼────────────┼────────────┼─────────────────────────────────┼─────────────────────────────────┤\n",
      "│ 9.5        │ 138.0      │ 73.0       │ 11.0        │ 276.0      │ 120.0      │ Bad                             │ 42.0       │ 17.0       │ Yes                             │ Yes                             │\n",
      "│ 11.22      │ 111.0      │ 48.0       │ 16.0        │ 260.0      │ 83.0       │ Good                            │ 65.0       │ 10.0       │ Yes                             │ Yes                             │\n",
      "│ 10.06      │ 113.0      │ 35.0       │ 10.0        │ 269.0      │ 80.0       │ Medium                          │ 59.0       │ 12.0       │ Yes                             │ Yes                             │\n",
      "└────────────┴────────────┴────────────┴─────────────┴────────────┴────────────┴─────────────────────────────────┴────────────┴────────────┴─────────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "using MLJ\n",
    "import RDatasets: dataset\n",
    "using PrettyPrinting\n",
    "import DataFrames: DataFrame, select, Not\n",
    "\n",
    "DTC = @load DecisionTreeClassifier pkg = DecisionTree\n",
    "\n",
    "carseats = dataset(\"ISLR\", \"Carseats\")\n",
    "\n",
    "first(carseats, 3) |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e6b52",
   "metadata": {},
   "source": [
    "We encode a new variable High based on whether the sales are higher or lower than 8 and add that column to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5519e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{String}:\n",
       " \"Sales\"\n",
       " \"CompPrice\"\n",
       " \"Income\"\n",
       " \"Advertising\"\n",
       " \"Population\"\n",
       " \"Price\"\n",
       " \"ShelveLoc\"\n",
       " \"Age\"\n",
       " \"Education\"\n",
       " \"Urban\"\n",
       " \"US\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(carseats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29c64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "High = ifelse.(carseats.Sales .<= 8, \"No\", \"Yes\") |> categorical;\n",
    "carseats[!, :High] = High;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f463c12f",
   "metadata": {},
   "source": [
    "Let's now train a basic decision tree classifier for ```High``` given the other features after one-hot-encoding the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bb80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = select(carseats, Not([:Sales, :High]))\n",
    "y = carseats.High;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e1bc",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3a5049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{ProbabilisticPipeline{NamedTuple{,…},…},…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Training Machine{OneHotEncoder,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Spawning 3 sub-features to one-hot encode feature :ShelveLoc.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :Urban.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :US.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Training Machine{DecisionTreeClassifier,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n"
     ]
    }
   ],
   "source": [
    "HotTreeClf = OneHotEncoder() |> DTC()\n",
    "\n",
    "mdl = HotTreeClf\n",
    "mach = machine(mdl, X, y)\n",
    "fit!(mach);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991b41a",
   "metadata": {},
   "source": [
    "Note ```|>``` is syntactic sugar for creating a ```Pipeline``` model from component model instances or model types. Note also that the machine ```mach``` is trained on the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650819f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_mode(mach, X)\n",
    "misclassification_rate(ypred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264d52b",
   "metadata": {},
   "source": [
    "That's right... it gets it perfectly; this tends to be classic behaviour for a DTC to overfit the data it's trained on. Let's see if it generalises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27941881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{ProbabilisticPipeline{NamedTuple{,…},…},…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Training Machine{OneHotEncoder,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Spawning 3 sub-features to one-hot encode feature :ShelveLoc.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :Urban.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :US.\n",
      "└ @ MLJModels C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\builtins\\Transformers.jl:1142\n",
      "┌ Info: Training Machine{DecisionTreeClassifier,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = partition(eachindex(y), 0.5, shuffle = true, rng = 333)\n",
    "fit!(mach, rows = train)\n",
    "ypred = predict_mode(mach, rows = test)\n",
    "misclassification_rate(ypred, y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f8d70",
   "metadata": {},
   "source": [
    "Not really..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2360f",
   "metadata": {},
   "source": [
    "### Tuning a DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5946184",
   "metadata": {},
   "source": [
    "Let's try to do a bit of tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcee6ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{ProbabilisticTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Attempting to evaluate 64 models.\n",
      "└ @ MLJTuning C:\\Users\\jeffr\\.julia\\packages\\MLJTuning\\Al9yX\\src\\tuned_models.jl:680\n",
      "\u001b[33mEvaluating over 64 metamodels: 100%[=========================] Time: 0:00:02\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{ProbabilisticTunedModel{Grid,…},…} trained 1 time; caches data\n",
       "  model: MLJTuning.ProbabilisticTunedModel{Grid, MLJBase.ProbabilisticPipeline{NamedTuple{(:one_hot_encoder, :decision_tree_classifier), Tuple{Unsupervised, Probabilistic}}, MLJModelInterface.predict}}\n",
       "  args: \n",
       "    1:\tSource @616 ⏎ `Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{2}}}}`\n",
       "    2:\tSource @505 ⏎ `AbstractVector{Multiclass{2}}`\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mpi = range(mdl, :(decision_tree_classifier.max_depth), lower = 1, upper = 10)\n",
    "r_msi = range(mdl, :(decision_tree_classifier.min_samples_leaf), lower = 1, upper = 50)\n",
    "\n",
    "tm = TunedModel(model = mdl, \n",
    "                ranges = [r_mpi, r_msi],\n",
    "                tuning = Grid(resolution = 8),\n",
    "                resampling = CV(nfolds = 5, rng = 112),\n",
    "                operation = predict_mode,\n",
    "                measure = misclassification_rate)\n",
    "\n",
    "mtm = machine(tm, X, y)\n",
    "fit!(mtm, rows = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c4d705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_mode(mtm, rows = test)\n",
    "misclassification_rate(ypred, y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d182b9a",
   "metadata": {},
   "source": [
    "We can inspect the parameters of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37301063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = 5,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5,\n",
       "    rng = Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mtm).best_model.decision_tree_classifier # max_depth = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331c3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticPipeline(\n",
       "    one_hot_encoder = OneHotEncoder(\n",
       "            features = Symbol[],\n",
       "            drop_last = false,\n",
       "            ordered_factor = true,\n",
       "            ignore = false),\n",
       "    decision_tree_classifier = DecisionTreeClassifier(\n",
       "            max_depth = 5,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = false,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            pdf_smoothing = 0.0,\n",
       "            display_depth = 5,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    cache = true)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mtm).best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c52908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(best_model = ProbabilisticPipeline{NamedTuple{,…},…},\n",
       " best_fitted_params = (decision_tree_classifier = (tree = Decision Tree\n",
       "Leaves: 15\n",
       "Depth:  5,\n",
       "                                                   encoding = Dict{CategoricalArrays.CategoricalValue{String, UInt32}, UInt32}(\"Yes\" => 0x00000002, \"No\" => 0x00000001),),\n",
       "                       one_hot_encoder = (fitresult = OneHotEncoderResult,),\n",
       "                       machines = Machine[Machine{OneHotEncoder,…}, Machine{DecisionTreeClassifier,…}],\n",
       "                       fitted_params_given_machine = OrderedCollections.LittleDict{Any, Any, Vector{Any}, Vector{Any}}(Machine{OneHotEncoder,…} => (fitresult = OneHotEncoderResult,), Machine{DecisionTreeClassifier,…} => (tree = Decision Tree\n",
       "Leaves: 15\n",
       "Depth:  5, encoding = Dict{CategoricalArrays.CategoricalValue{String, UInt32}, UInt32}(\"Yes\" => 0x00000002, \"No\" => 0x00000001))),),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ca819",
   "metadata": {},
   "source": [
    "### Decisioin Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4226b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR = @load DecisionTreeRegressor pkg = DecisionTree\n",
    "\n",
    "boston = dataset(\"MASS\", \"Boston\")\n",
    "\n",
    "y, X = unpack(boston, ==(:MedV))\n",
    "\n",
    "train, test = partition(eachindex(y), 0.5, shuffle = true, rng = 551)\n",
    "\n",
    "scitype(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1c77c",
   "metadata": {},
   "source": [
    "Let's recode the Count as Continuous and then fit a DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2665438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬────────────┬─────────┐\n",
       "│\u001b[22m names   \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├─────────┼────────────┼─────────┤\n",
       "│ Crim    │ Continuous │ Float64 │\n",
       "│ Zn      │ Continuous │ Float64 │\n",
       "│ Indus   │ Continuous │ Float64 │\n",
       "│ Chas    │ Count      │ Int64   │\n",
       "│ NOx     │ Continuous │ Float64 │\n",
       "│ Rm      │ Continuous │ Float64 │\n",
       "│ Age     │ Continuous │ Float64 │\n",
       "│ Dis     │ Continuous │ Float64 │\n",
       "│ Rad     │ Count      │ Int64   │\n",
       "│ Tax     │ Count      │ Int64   │\n",
       "│ PTRatio │ Continuous │ Float64 │\n",
       "│ Black   │ Continuous │ Float64 │\n",
       "│ LStat   │ Continuous │ Float64 │\n",
       "└─────────┴────────────┴─────────┘\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae8360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{DecisionTreeRegressor,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{DecisionTreeRegressor,…} trained 1 time; caches data\n",
       "  model: MLJDecisionTreeInterface.DecisionTreeRegressor\n",
       "  args: \n",
       "    1:\tSource @967 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @792 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = coerce(X, autotype(X, rules = (:discrete_to_continuous, )))\n",
    "\n",
    "dtr_model = DTR()\n",
    "dtr = machine(dtr_model, X, y)\n",
    "\n",
    "fit!(dtr, rows = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58618483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.98"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = MLJ.predict(dtr, rows = test)\n",
    "round(rms(ypred, y[test]), sigdigits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31fdb1",
   "metadata": {},
   "source": [
    "Again we can try tuning this a bit, since it's the same idea as before, let's just try to adjust the depth of the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f08da1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericRange(2 ≤ max_depth ≤ 20; origin=11.0, unit=9.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_depth = range(dtr_model, :max_depth, lower = 2, upper = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5970f51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeterministicTunedModel(\n",
       "    model = DecisionTreeRegressor(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 5,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = 0,\n",
       "            post_prune = false,\n",
       "            merge_purity_threshold = 1.0,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    tuning = Grid(\n",
       "            goal = nothing,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = CV(\n",
       "            nfolds = 5,\n",
       "            shuffle = true,\n",
       "            rng = Random.MersenneTwister(1254)),\n",
       "    measure = RootMeanSquaredError(),\n",
       "    weights = nothing,\n",
       "    operation = nothing,\n",
       "    range = MLJBase.NumericRange{Int64, MLJBase.Bounded, Symbol}[NumericRange(2 ≤ max_depth ≤ 20; origin=11.0, unit=9.0)],\n",
       "    selection_heuristic = MLJTuning.NaiveSelection(nothing),\n",
       "    train_best = true,\n",
       "    repeats = 1,\n",
       "    n = nothing,\n",
       "    acceleration = CPU1{Nothing}(nothing),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true,\n",
       "    cache = true)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = TunedModel(model = dtr_model, \n",
    "                ranges = [r_depth],\n",
    "                tuning = Grid(resolution = 10),\n",
    "                resampling = CV(nfolds = 5, rng = 1254),\n",
    "                measure = rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4488e706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{DeterministicTunedModel{Grid,…},…} trained 0 times; caches data\n",
       "  model: MLJTuning.DeterministicTunedModel{Grid, MLJDecisionTreeInterface.DecisionTreeRegressor}\n",
       "  args: \n",
       "    1:\tSource @419 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @085 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtm = machine(tm, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4c1795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{DeterministicTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Info: Attempting to evaluate 10 models.\n",
      "└ @ MLJTuning C:\\Users\\jeffr\\.julia\\packages\\MLJTuning\\Al9yX\\src\\tuned_models.jl:680\n",
      "\u001b[33mEvaluating over 10 metamodels: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{DeterministicTunedModel{Grid,…},…} trained 1 time; caches data\n",
       "  model: MLJTuning.DeterministicTunedModel{Grid, MLJDecisionTreeInterface.DecisionTreeRegressor}\n",
       "  args: \n",
       "    1:\tSource @419 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @085 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mtm, rows = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85c6eaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = MLJ.predict(mtm, rows = test)\n",
    "round(rms(ypred, y[test]), sigdigits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5abfee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(\n",
       "    max_depth = 6,\n",
       "    min_samples_leaf = 5,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    rng = Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mtm).best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0416b",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "**Note** : the package DecisionTree.jl also has a RandomForest model but it is not yet interfaced with in MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb360eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJScikitLearnInterface"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJScikitLearnInterface.RandomForestRegressor"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR = @load RandomForestRegressor pkg=ScikitLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5e8e25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{RandomForestRegressor,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "┌ Warning: `vendor()` is deprecated, use `BLAS.get_config()` and inspect the output instead\n",
      "│   caller = npyinitialize() at numpy.jl:67\n",
      "└ @ PyCall C:\\Users\\jeffr\\.julia\\packages\\PyCall\\L0fLP\\src\\numpy.jl:67\n",
      "C:\\Users\\jeffr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\jeffr\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{RandomForestRegressor,…} trained 1 time; caches data\n",
       "  model: MLJScikitLearnInterface.RandomForestRegressor\n",
       "  args: \n",
       "    1:\tSource @511 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @867 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mdl = RFR()\n",
    "rf = machine(rf_mdl, X, y)\n",
    "fit!(rf, rows = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5ad93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.83"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = MLJ.predict(rf, rows = test)\n",
    "round(rms(ypred, y[test]), sigdigits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592893d4",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d090b4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\jeffr\\.julia\\packages\\MLJModels\\tMgLW\\src\\loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJXGBoostInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{XGBoostRegressor,…}.\n",
      "└ @ MLJBase C:\\Users\\jeffr\\.julia\\packages\\MLJBase\\MuLnJ\\src\\machines.jl:464\n",
      "[1]\ttrain-rmse:17.455181\n",
      "[2]\ttrain-rmse:12.624966\n",
      "[3]\ttrain-rmse:9.235101\n",
      "[4]\ttrain-rmse:6.827576\n",
      "[5]\ttrain-rmse:5.102226\n",
      "[6]\ttrain-rmse:3.865698\n",
      "[7]\ttrain-rmse:2.960039\n",
      "[8]\ttrain-rmse:2.282763\n",
      "[9]\ttrain-rmse:1.794703\n",
      "[10]\ttrain-rmse:1.432438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{XGBoostRegressor,…} trained 1 time; caches data\n",
       "  model: MLJXGBoostInterface.XGBoostRegressor\n",
       "  args: \n",
       "    1:\tSource @555 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @481 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBR = @load XGBoostRegressor\n",
    "\n",
    "xgb_mdl = XGBR(num_round = 10, max_depth = 10)\n",
    "xgb = machine(xgb_mdl, X, y)\n",
    "fit!(xgb, rows = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a732db98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.96"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = MLJ.predict(xgb, rows = test)\n",
    "round(rms(ypred, y[test]), sigdigits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29d2b5",
   "metadata": {},
   "source": [
    "Again we could do some tuning for this."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
